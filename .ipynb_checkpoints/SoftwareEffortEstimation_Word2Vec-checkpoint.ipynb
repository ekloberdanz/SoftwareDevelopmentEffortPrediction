{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "i5htc4V9FWoz",
    "outputId": "6d5f02ae-e081-4142-c5e3-07d25d1601e1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issuekey</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>storypoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STUDIO-95</td>\n",
       "      <td>Support for request/reply</td>\n",
       "      <td>request/reply  http://www.mulesoft.org/documen...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STUDIO-280</td>\n",
       "      <td>Cannot import a Studio project from Git withou...</td>\n",
       "      <td>Steps to reproduce:    1. Create a simple Mule...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STUDIO-382</td>\n",
       "      <td>Changes to Java code do not get hot deployed</td>\n",
       "      <td>Java source changes don't get picked up right ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STUDIO-459</td>\n",
       "      <td>Unable to add a response when creating a secon...</td>\n",
       "      <td>Unable to add a response when creating a secon...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STUDIO-618</td>\n",
       "      <td>Namespaces in the XML view are not being remo...</td>\n",
       "      <td>When you add an element and then you remove it...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>STUDIO-781</td>\n",
       "      <td>Would save time to be given the option to crea...</td>\n",
       "      <td>Add a button in the ClassFieldEditor to create...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     issuekey                                              title  \\\n",
       "0   STUDIO-95                          Support for request/reply   \n",
       "1  STUDIO-280  Cannot import a Studio project from Git withou...   \n",
       "2  STUDIO-382       Changes to Java code do not get hot deployed   \n",
       "3  STUDIO-459  Unable to add a response when creating a secon...   \n",
       "4  STUDIO-618   Namespaces in the XML view are not being remo...   \n",
       "5  STUDIO-781  Would save time to be given the option to crea...   \n",
       "\n",
       "                                         description  storypoint  \n",
       "0  request/reply  http://www.mulesoft.org/documen...          13  \n",
       "1  Steps to reproduce:    1. Create a simple Mule...           3  \n",
       "2  Java source changes don't get picked up right ...           5  \n",
       "3  Unable to add a response when creating a secon...           8  \n",
       "4  When you add an element and then you remove it...           8  \n",
       "5  Add a button in the ClassFieldEditor to create...           5  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load Data\n",
    "url = 'https://raw.githubusercontent.com/SEAnalytics/datasets/master/storypoint/IEEE%20TSE2018/dataset/mulestudio.csv'\n",
    "raw_data = pd.read_csv(url)\n",
    "raw_data.columns\n",
    "raw_data.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "io_XhNMpHRDG",
    "outputId": "5369611e-218f-4e79-888a-b22f5cb3c8a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "issuekey       0\n",
       "title          0\n",
       "description    0\n",
       "storypoint     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "raw_data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "colab_type": "code",
    "id": "FTRFliXiIDzF",
    "outputId": "cad29dd8-d728-4f52-cf60-ca77aea10c09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    732.000000\n",
       "mean       6.396175\n",
       "std        5.385687\n",
       "min        1.000000\n",
       "25%        3.000000\n",
       "50%        5.000000\n",
       "75%        8.000000\n",
       "max       34.000000\n",
       "Name: storypoint, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Examine storypoints summary statistics\n",
    "raw_data.storypoint.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "7mwYp4JTITqW",
    "outputId": "99a2e71e-1b86-4fc5-997b-1a949c8d86bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize number of storypoints distribution\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(raw_data.storypoint, bins=20, alpha=0.6, color='b')\n",
    "plt.title(\"#Items per Point\")\n",
    "plt.xlabel(\"Points\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "zJlSZo91I22w",
    "outputId": "2bd58cc0-08ca-4881-d7a4-ae39bbd681a0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Zoom in on most common data representing 75% of the dataset\n",
    "import numpy as np\n",
    "frequent_data = raw_data.query('storypoint <= 8')\n",
    "plt.hist(frequent_data.storypoint, bins=20, alpha=0.6, color='b')\n",
    "plt.title(\"#Items per Point\")\n",
    "plt.xlabel(\"Points\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(np.arange(0, 10, 1)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.loc[raw_data.storypoint <= 2, 'storypoint'] = 0 #small\n",
    "raw_data.loc[(raw_data.storypoint > 2) & (raw_data.storypoint <= 5), 'storypoint'] = 1 #medium\n",
    "raw_data.loc[raw_data.storypoint > 5, 'storypoint'] = 2 #big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "id": "nz9dOQdOMtPG",
    "outputId": "dfa42c8f-55bd-4438-a867-0bc745251188"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "storypoint\n",
       "0    126\n",
       "1    344\n",
       "2    262\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine distribution in detail\n",
    "raw_data.groupby('storypoint').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eZXJYGV2NOKd"
   },
   "source": [
    "This shows that 5 the most common number of storypoints assigned to an issue/requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "heESOd6eNrhh",
    "outputId": "956b9c7e-f0ed-4a84-ba5c-87bbca18f050"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/eliska/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/eliska/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "################### Data Preprocessing ###################################\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "issue_titles = raw_data['title']\n",
    "issue_descriptions = raw_data['description']\n",
    "\n",
    "# Create a list of strings, one for each title\n",
    "titles_list = [title for title in issue_titles]\n",
    "descriptions_list = [description for description in issue_descriptions]\n",
    "\n",
    "# Collapse the list of strings into a single long string for processing\n",
    "big_title_string = ' '.join(titles_list)\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Tokenize the string into words\n",
    "tokens = word_tokenize(big_title_string)\n",
    "\n",
    "# Remove non-alphabetic tokens, such as punctuation\n",
    "words = [word.lower() for word in tokens if word.isalpha()]\n",
    "\n",
    "# Filter out stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [word for word in words if not word in stop_words]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "id": "m4dZhPsZHvTQ",
    "outputId": "b3dd76d2-bb08-42c4-acef-1568f7a74f6d"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "# Load word2vec model (trained on an enormous Google corpus)\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz', binary = True) \n",
    "\n",
    "# Check dimension of word vectors\n",
    "model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "C_lhaxc2JUR3",
    "outputId": "32ffc6a0-3e99-4d32-9d6d-29799bb971aa"
   },
   "outputs": [],
   "source": [
    "# Filter the list of vectors to include only those that Word2Vec has a vector for\n",
    "vector_list = [model[word] for word in words if word in model.vocab]\n",
    "\n",
    "# Create a list of the words corresponding to these vectors\n",
    "words_filtered = [word for word in words if word in model.vocab]\n",
    "\n",
    "# Zip the words together with their vector representations\n",
    "word_vec_zip = zip(words_filtered, vector_list)\n",
    "\n",
    "# Cast to a dict so we can turn it into a DataFrame\n",
    "word_vec_dict = dict(word_vec_zip)\n",
    "df = pd.DataFrame.from_dict(word_vec_dict, orient='index')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "IFWCW_Qmqktq",
    "outputId": "c156a3fd-5bd2-4ccb-aa37-56d59d449c6a"
   },
   "outputs": [],
   "source": [
    "# Vocabulary\n",
    "vocabulary = set(words) # list of unique words\n",
    "vocabulary_size = len(vocabulary)\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "OeRaact5A21z",
    "outputId": "0bb92a7d-101b-4f3b-d9a4-20b637d0a254"
   },
   "outputs": [],
   "source": [
    "# Total Number of Words\n",
    "len(words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "colab_type": "code",
    "id": "Eoe7uNnJBP57",
    "outputId": "10303085-4dd1-403f-9fc7-b4137b195068"
   },
   "outputs": [],
   "source": [
    "# Frequency Distribution of Words Plot\n",
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist(words)\n",
    "import matplotlib.pyplot as plt\n",
    "fdist.plot(30,cumulative=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "colab_type": "code",
    "id": "oEQF8jyfOHSs",
    "outputId": "bac1d114-fb0d-42f5-f1e3-d244c10d5f71"
   },
   "outputs": [],
   "source": [
    "# Dimentionality Reduction\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Initialize t-SNE\n",
    "tsne = TSNE(n_components = 2, init = 'random', random_state = 10, perplexity = 100)\n",
    "# Use only 400 rows to shorten processing time\n",
    "tsne_df = tsne.fit_transform(df[:400])\n",
    "\n",
    "# Plot\n",
    "import seaborn as sns\n",
    "sns.set()# Initialize figure\n",
    "fig, ax = plt.subplots(figsize = (11.7, 8.27))\n",
    "sns.scatterplot(tsne_df[:, 0], tsne_df[:, 1], alpha = 0.5)\n",
    "\n",
    "# Import adjustText, initialize list of texts\n",
    "#from adjustText import adjust_text\n",
    "texts = []\n",
    "words_to_plot = list(np.arange(0, 400, 10))\n",
    "\n",
    "# Append words to list\n",
    "for word in words_to_plot:\n",
    "    texts.append(plt.text(tsne_df[word, 0], tsne_df[word, 1], df.index[word], fontsize = 14))\n",
    "    \n",
    "# Plot text using adjust_text (because overlapping text is hard to read)\n",
    "'''\n",
    "adjust_text(texts, force_points = 0.4, force_text = 0.4, \n",
    "            expand_points = (2,1), expand_text = (1,2),\n",
    "            arrowprops = dict(arrowstyle = \"-\", color = 'black', lw = 0.5))\n",
    "'''\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5obddvrdfJEr"
   },
   "outputs": [],
   "source": [
    "raw_data['storypoint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bSNDGC3cS8i3"
   },
   "outputs": [],
   "source": [
    "# Averaging Word Embeddings\n",
    "def document_vector(word2vec_model, doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    doc = [word for word in doc if word in model.vocab]\n",
    "    return np.mean(model[doc], axis=0)\n",
    "\n",
    "# Our earlier preprocessing was done when we were dealing only with word vectors\n",
    "# Here, we need each document to remain a document \n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    doc = word_tokenize(text)\n",
    "    doc = [word for word in doc if word not in stop_words]\n",
    "    doc = [word for word in doc if word.isalpha()] \n",
    "    return doc\n",
    "\n",
    "# Function that will help us drop documents that have no word vectors in word2vec\n",
    "def has_vector_representation(word2vec_model, doc):\n",
    "    \"\"\"check if at least one word of the document is in the\n",
    "    word2vec dictionary\"\"\"\n",
    "    return not all(word not in word2vec_model.vocab for word in doc)\n",
    "\n",
    "# Filter out documents\n",
    "def filter_docs(corpus, texts, condition_on_doc):\n",
    "    \"\"\"\n",
    "    Filter corpus and texts given the function condition_on_doc which takes a doc. The document doc is kept if condition_on_doc(doc) is true.\n",
    "    \"\"\"\n",
    "    number_of_docs = len(corpus)\n",
    "\n",
    "    if texts is not None:\n",
    "        texts = [text for (text, doc) in zip(texts, corpus)\n",
    "                 if condition_on_doc(doc)]\n",
    "\n",
    "    corpus = [doc for doc in corpus if condition_on_doc(doc)]\n",
    "\n",
    "    print(\"{} docs removed\".format(number_of_docs - len(corpus)))\n",
    "\n",
    "    return (corpus, texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "0aUMd0sefCfl",
    "outputId": "2d3740e2-bdb4-402c-c23a-71c7a3ec912e"
   },
   "outputs": [],
   "source": [
    "raw_data['storypoint'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FPfdl3qiTZIZ"
   },
   "outputs": [],
   "source": [
    "# Preprocess the corpus\n",
    "def preprocessing(data_list):\n",
    "  corpus = [preprocess(title) for title in data_list]\n",
    "\n",
    "  # Remove docs that don't include any words in W2V's vocab\n",
    "  corpus, data_list = filter_docs(corpus, data_list, lambda doc: has_vector_representation(model, doc))\n",
    "\n",
    "  # Filter out any empty docs\n",
    "  corpus, data_list = filter_docs(corpus, data_list, lambda doc: (len(doc) != 0))\n",
    "\n",
    "  y = []\n",
    "  x = []\n",
    "  for doc in corpus: # append the vector for each document\n",
    "      #print(corpus.index(doc))\n",
    "      x.append(document_vector(model, doc))\n",
    "      y.append(raw_data['storypoint'][corpus.index(doc)])\n",
    "      \n",
    "  X = np.array(x) # list to array\n",
    "  y = np.array(y)\n",
    "  return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "JL_LxUkOdjhu",
    "outputId": "f449905a-9cc7-4b24-de10-78b6e9d6d52c"
   },
   "outputs": [],
   "source": [
    "# Titles\n",
    "X = preprocessing(titles_list)[0]\n",
    "y = preprocessing(titles_list)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CKjZXX5MUBrU"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 80% of data goes to training\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g4dJ64r2YP34"
   },
   "source": [
    "XGBRegressor - using Titles of software issues/requests as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "An185tj6UZ1C",
    "outputId": "e6c2e3a5-5503-405e-8021-3d69e5094939"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "# Instantiate an XGBRegressor\n",
    "xgr = xgb.XGBRegressor(random_state=2)\n",
    "\n",
    "# Fit the classifier to the training set\n",
    "xgr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgr.predict(X_test)\n",
    "\n",
    "mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Accuracy\n",
    "y_pred_rounded = [round(prediction,0) for prediction in y_pred ]\n",
    "y_pred_rounded = [int(prediction) for prediction in y_pred_rounded]\n",
    "\n",
    "from sklearn import metrics\n",
    "acc_score = metrics.accuracy_score(y_test, y_pred_rounded)\n",
    "print('Total accuracy classification score: {}'.format(acc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EF3Hu53dYRhE"
   },
   "source": [
    "GaussianNB - - using Titles of software issues/requests as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "28xVzDV7VFMk",
    "outputId": "5bc46355-d7b8-4049-e735-984e9e9de870"
   },
   "outputs": [],
   "source": [
    "# Build the classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "\n",
    "# Fit the classifier to the training set\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "from sklearn import metrics\n",
    "acc_score = metrics.accuracy_score(y_test, y_pred)\n",
    "print('Total accuracy classification score: {}'.format(acc_score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mT3WtmMIg-cc"
   },
   "source": [
    "Using Descriptions of sotware issues/requests as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "4ijKXyELguar",
    "outputId": "f9a382a4-5a7d-499e-ce82-88038cfbb614"
   },
   "outputs": [],
   "source": [
    "# Descriptions\n",
    "X = preprocessing(descriptions_list)[0]\n",
    "y = preprocessing(descriptions_list)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eNRlUIwPhPsf"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 80% of data goes to training\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "giCa6_qng8WF",
    "outputId": "243bff81-e8ae-4f19-a734-dca2d0e14e04"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "# Instantiate an XGBRegressor\n",
    "xgr = xgb.XGBRegressor(random_state=2)\n",
    "\n",
    "# Fit the classifier to the training set\n",
    "xgr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgr.predict(X_test)\n",
    "\n",
    "mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Accuracy\n",
    "y_pred_rounded = [round(prediction,0) for prediction in y_pred ]\n",
    "y_pred_rounded = [int(prediction) for prediction in y_pred_rounded]\n",
    "\n",
    "from sklearn import metrics\n",
    "acc_score = metrics.accuracy_score(y_test, y_pred_rounded)\n",
    "print('Total accuracy classification score: {}'.format(acc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_KVUtnrehIQy",
    "outputId": "6149c67d-7867-499c-c742-07e8aeae4602"
   },
   "outputs": [],
   "source": [
    "# Build the classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "\n",
    "# Fit the classifier to the training set\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "from sklearn import metrics\n",
    "acc_score = metrics.accuracy_score(y_test, y_pred)\n",
    "print('Total accuracy classification score: {}'.format(acc_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "WNu1-LKomOwE",
    "outputId": "04bcc957-95d0-47cc-bcd3-3658a9079b59"
   },
   "outputs": [],
   "source": [
    "y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SoftwareEffortEstimation_Word2Vec.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
